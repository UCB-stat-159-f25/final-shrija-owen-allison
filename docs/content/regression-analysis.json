{"version":3,"kind":"Notebook","sha256":"f1aa17863e9719edda63087273f405422127955ba4c5535bd4cf73fc57607be0","slug":"regression-analysis","location":"/regression_analysis.ipynb","dependencies":[],"frontmatter":{"title":"Logistic Regression Model","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"Shrija","family":"Shrija"},"name":"Shrija","id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"Owen","family":"Owen"},"name":"Owen","id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"Allison","family":"Allison"},"name":"Allison","id":"contributors-myst-generated-uid-2"}],"github":"https://github.com/UCB-stat-159-f25/final-shrija-owen-allison","source_url":"https://github.com/UCB-stat-159-f25/final-shrija-owen-allison/blob/main/regression_analysis.ipynb","edit_url":"https://github.com/UCB-stat-159-f25/final-shrija-owen-allison/edit/main/regression_analysis.ipynb","exports":[{"format":"ipynb","filename":"regression_analysis.ipynb","url":"/regression_analysis-312e1efb7779e05eca98652038987267.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In this notebook, we wanted to see how accurate of a logostic model we could make using our most significant variables from our exploratory analysis. The goal of this model is to predict whether a student will graduate given their age at enrollement, whether they’re in debt, and whether they’re up to date on their tuition fees.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dWDMx2dDd6"}],"key":"opsG7tpdIB"}],"key":"vtRD1hg1sw"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\ndata_dir = Path(\"data\")\noutputs_dir = Path(\"outputs\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler","key":"KJPXnGuIpD"},{"type":"outputs","id":"R8reswlDCqcz2YgqNf4yc","children":[],"key":"aO5amR2ezH"}],"key":"wgwe9xecEH"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Loading and Cleaning Data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kkio9oNyHn"}],"identifier":"loading-and-cleaning-data","label":"Loading and Cleaning Data","html_id":"loading-and-cleaning-data","implicit":true,"key":"oHyDzLNNco"}],"key":"wj6uPF3UUK"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Load data\nstudent_data = pd.read_csv(data_dir/\"student_data.csv\", sep = \";\" )\n# Select columns\nmodel_sd = student_data[['Debtor', 'Age at enrollment', 'Tuition fees up to date', 'Target']]\n# Remove enrolled students\nmodel_sd = model_sd[model_sd[\"Target\"] != \"Enrolled\"]\n\n# Map Target column values\nmodel_sd[\"Target\"] = model_sd[\"Target\"].replace({\"Graduate\": 1, \"Dropout\": 0})","key":"LyzvCkrtvc"},{"type":"outputs","id":"hTyeGzYIwvKPalRh96fBw","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_13120/2869028448.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  model_sd[\"Target\"] = model_sd[\"Target\"].replace({\"Graduate\": 1, \"Dropout\": 0})\n"},"children":[],"key":"cR1hSBDMpo"}],"key":"GLwhv8Tw8r"}],"key":"w5QHpznACj"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Building Model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aix9y8AJaF"}],"identifier":"building-model","label":"Building Model","html_id":"building-model","implicit":true,"key":"hSYwFthARx"}],"key":"UrRrjCF4TD"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Separating Features and Target\nX = model_sd.drop(\"Target\", axis = 1)\ny = model_sd[\"Target\"]\n\n# Training and Test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 67)\n\n# Scale model variables\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Train model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predictions\ny_pred = model.predict(X_test)","key":"Dhf2jPUDQX"},{"type":"outputs","id":"_uY9NQ4LPsRgKS9hoWel7","children":[],"key":"c70srv4mqM"}],"key":"CKkFiShRKo"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Evaluate Model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Q2CfX5qR1p"}],"identifier":"evaluate-model","label":"Evaluate Model","html_id":"evaluate-model","implicit":true,"key":"WlCI5s6yBO"}],"key":"LT4AJP3fvF"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Evaluate model\naccuracy = accuracy_score(y_test, y_pred)\nmatrix = confusion_matrix(y_test, y_pred)\nreport = classification_report(y_test, y_pred)\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Confusion Matrix: {matrix}\")\nprint(f\"Classification Report: {report}\")","key":"QLTcOB6hXd"},{"type":"outputs","id":"jexvnyUSRudhw3qscpH3F","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Accuracy: 0.7245179063360881\nConfusion Matrix: [[119 181]\n [ 19 407]]\nClassification Report:               precision    recall  f1-score   support\n\n           0       0.86      0.40      0.54       300\n           1       0.69      0.96      0.80       426\n\n    accuracy                           0.72       726\n   macro avg       0.78      0.68      0.67       726\nweighted avg       0.76      0.72      0.70       726\n\n"},"children":[],"key":"HDyJOEM99k"}],"key":"ehQfyyRqqe"}],"key":"UN923lhKss"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Analysis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"M07uLafdm4"}],"identifier":"analysis","label":"Analysis","html_id":"analysis","implicit":true,"key":"QFDkXtmPeF"}],"key":"Mz4nLCdObC"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"With an accuracy of 72% our model proved capable but certainly not perfect. Our confusion matrix gave us a slightly more informative picture into where our model worked well: of all graduates, only 19 were misclassified as dropouts. On the other hand, our model misclassified more dropouts as graduates than it was able to correctly label. In other words, and as our precision and recall further confirm as well, our model was very good at identifying all true graduates but labeled too many students as graduates as a consequence. While these results are also certainly impacted by the randomness of our sampled data and the randomness of our training and test split while building our model, it left us with an informative conclusion: our selected student factors (age at enrollment, if they’re a debtor, and if they’re tuition fees are up to date) all are better for a model intended to predict if a student will graduate, rather than identify students at risk of dropping out of school. This conclusion is clear given our model’s bias towards predicting a student will graduate, and failure to effectively find which students would go on to drop out of school.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iZf51YcLvq"}],"key":"eDNThoMMso"}],"key":"rBfjJVbRMW"}],"key":"hKP99o6S7F"},"references":{"cite":{"order":[],"data":{}}}}